{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"drive/MyDrive/Colab Notebooks\")"
      ],
      "metadata": {
        "id": "53XXnPTTAWRW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddb6749-fe90-41f5-a63a-80610a10713f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "fCksCPnjQxE2"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# map the data into the [0,1] range (convert to float!) and convert the labels to int32\n",
        "def preprocess_images(images):\n",
        "    return images.reshape(-1, 784).astype(np.float32) / 255\n",
        "\n",
        "def preprocess_labels(labels):\n",
        "    return labels.reshape(-1).astype(np.int32)\n",
        "\n",
        "train_images = preprocess_images(train_images)\n",
        "test_images = preprocess_images(test_images)\n",
        "train_labels = preprocess_labels(train_labels)\n",
        "test_labels = preprocess_labels(test_labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "[https://stackoverflow.com/questions/53514495/what-does-batch-repeat-and-shuffle-do-with-tensorflow-dataset](https://)\n",
        "[https://stats.stackexchange.com/questions/245502/why-should-we-shuffle-data-while-training-a-neural-network/311318#311318](https://)\n",
        "\n",
        "Repeat:\n",
        "It will make dataset re-initialize after each iteration\n",
        "producing indefinite sequence of elements.\n",
        "\n",
        "Batch:\n",
        "will take the first batch_size entries and make a batch out of them.\n",
        "\n",
        "it helps the training converge fast,prevents any bias during the training,prevents the model from learning the order of the training\n"
      ],
      "metadata": {
        "id": "WyvmE_MUj8gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle:\n",
        "# Random buffer\n",
        "#    |\n",
        "#    |   Source dataset where all other elements live\n",
        "#    |         |\n",
        "#    ↓         ↓\n",
        "# [1,2,3] <= [4,5,6]\n",
        "train_data_1 = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).batch(128).repeat() \n",
        "train_data_2 = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(60000).repeat().batch(128) #best\n",
        "\n",
        "train_data_3 = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(128).shuffle(60000).repeat()\n",
        "train_data_4 = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(128).repeat().shuffle(60000) \n",
        "\n",
        "train_data_5 = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).repeat().shuffle(60000).batch(128)\n",
        "train_data_6 = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).repeat().batch(128).shuffle(60000)\n",
        "\n",
        "variables_train_data1 = [train_data_1, train_data_2, train_data_3, train_data_4, train_data_5, train_data_6]\n",
        "# variables_train_data2 = []\n",
        "\n",
        "# elems = 1\n",
        "# for train_data in variables_train_data1:\n",
        "#   for img_batch, lbl_batch in train_data:\n",
        "#     print(\"shape: {} and size: {} of train_data_{}\".format(train_data.shape, train_data.shape, elems))\n",
        "#     elems +=1\n",
        "\n",
        "\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(128)"
      ],
      "metadata": {
        "id": "GxF2IBnjj5iv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# here is an attempt at illustrating what flattening looks like\n",
        "reshaped = train_images[155].reshape((1, 28*28))\n",
        "plt.figure(figsize=(15, 0.1))\n",
        "plt.pcolormesh(reshaped, cmap=\"Greys_r\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CDgE5rnk5eJU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 57
        },
        "outputId": "1c8cdffb-dde1-4f6f-e15c-47dae49edad3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x7.2 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "lk_HB5JM5gXL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0bd18fd-b1dc-4bf6-bf22-d73b9e51a286"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784) (60000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Weight_0 = tf.Variable(tf.random.uniform(shape = [28*28, 256], minval = -0.1, maxval = 0.1, dtype = tf.dtypes.float32))\n",
        "bias_0 = tf.Variable(np.zeros(256, dtype=np.float32))\n",
        "Weight_2 = tf.Variable(tf.random.uniform(shape = [256, 10], minval = -0.1, maxval = 0.1, dtype = tf.dtypes.float32))\n",
        "bias_2 = tf.Variable(np.zeros(10, dtype=np.float32))\n",
        "\n",
        "\n",
        "def model(inputs):\n",
        "    output_0 = tf.nn.relu(tf.matmul(inputs, Weight_0) + bias_0)\n",
        "    output_2 = tf.nn.relu(tf.matmul(output_0, Weight_2) + bias_2)\n",
        "    return output_2\n",
        "\n",
        "\n",
        "train_steps = 2000\n",
        "learning_rate = 0.5\n",
        "from datetime import datetime\n",
        "logdir = os.path.join(\"logs\", \"linear\" + str(datetime.now()))\n",
        "train_writer = tf.summary.create_file_writer(os.path.join(logdir, \"train\"))\n",
        "test_writer = tf.summary.create_file_writer(os.path.join(logdir, \"test\"))"
      ],
      "metadata": {
        "id": "FpxVBGo05jfP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 1\n",
        "-------------------------------"
      ],
      "metadata": {
        "id": "XhZaemldPvnS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training loop\n",
        "# elems = 1\n",
        "\n",
        "# for train_data in variables_train_data1:\n",
        "for step, (image_batch, label_batch) in enumerate(train_data_2):\n",
        "  if step > train_steps:\n",
        "        break\n",
        "\n",
        "\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "      logits = model(image_batch)\n",
        "      xent = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "          logits=logits, labels=label_batch))\n",
        "      \n",
        "  grads_0 = tape.gradient(xent, [Weight_0, bias_0])\n",
        "  Weight_0.assign_sub(learning_rate * grads_0[0])\n",
        "  bias_0.assign_sub(learning_rate * grads_0[1])\n",
        "\n",
        "  grads_2 = tape.gradient(xent, [Weight_2, bias_2])\n",
        "  Weight_2.assign_sub(learning_rate * grads_2[0])\n",
        "  bias_2.assign_sub(learning_rate * grads_2[1])  \n",
        "\n",
        "  del tape\n",
        "  # every so often we print loss/accuracy\n",
        "  if not step % 500:\n",
        "      preds = tf.argmax(logits, axis=1, output_type=tf.int32)\n",
        "      acc = tf.reduce_mean(tf.cast(tf.equal(preds, label_batch),\n",
        "                            tf.float32))\n",
        "      print(\"Step {}. Batch loss: {} Batch accuracy: {}\".format(step+1, xent, acc))\n",
        "test_preds = tf.argmax(model(test_images), axis=1,\n",
        "                      output_type=tf.int32)\n",
        "acc = tf.reduce_mean(tf.cast(tf.equal(test_preds, test_labels),\n",
        "                            tf.float32))\n",
        "with train_writer.as_default():\n",
        "          tf.summary.scalar(\"accuracy\", acc, step=step)\n",
        "          tf.summary.image(\"input\", tf.reshape(image_batch, [-1, 28, 28, 1]), step=step)\n",
        "print(\"Test accuracy for train_data : {}\".format(acc))\n",
        "  # elems +=1"
      ],
      "metadata": {
        "id": "avSyb8NC5mDY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdea9a6e-e005-4ffa-effe-14a3aa9426eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1. Batch loss: 2.380023956298828 Batch accuracy: 0.0703125\n",
            "Step 501. Batch loss: 0.35799264907836914 Batch accuracy: 0.875\n",
            "Step 1001. Batch loss: 0.4522443413734436 Batch accuracy: 0.8125\n",
            "Step 1501. Batch loss: 0.06598906219005585 Batch accuracy: 0.984375\n",
            "Step 2001. Batch loss: 0.05237898975610733 Batch accuracy: 0.9765625\n",
            "Test accuracy for train_data : 0.9754999876022339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 2\n",
        "-------------------------------------------------\n",
        "repeat before shuffle leads to certain elements to be repeated before other elements appear even once\n",
        "\n",
        "shuffle before repeat slows down the performance\n",
        "\n",
        "batch before anything would create batches of the elements of the input dataset\n",
        "\n",
        "the optimal choice is shuffle, repeat, batch gurantees that all sample are processed in one epoch and continous generation of data in different ordering.\n"
      ],
      "metadata": {
        "id": "0G_AKZQk0E83"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TASK 3\n",
        "------------------------------------------------\n",
        "1.   Fail 1 \n",
        "\n",
        "> Issue ->Loss was Nan , because too many neurons exploding gradient issue occurs\n",
        "\n",
        "> Solution -> Reducing the number of neurons increased the accuracy to 94.3%\n",
        "\n",
        "2.   Fail 2\n",
        "\n",
        "> Issue ->Less accuracy because of sigmoid function\n",
        "\n",
        "> Solution -> Changing the activation function to Relu increased the accuracy to 92.7%\n",
        "\n",
        "3.   Fail 3\n",
        "\n",
        "> Issue ->range of weight was [-0.4,0]\n",
        "\n",
        "> Solution -> Changing the range [-0.4,0.4] , increases to 95.5%\n",
        "\n",
        "4.   Fail 4\n",
        "\n",
        "> Issue ->noise had a standard deviation of 4.0\n",
        "\n",
        "> Solution -> Changing the standard deviation to 0.1 increased the accuracy to 95.8%. \n",
        "\n",
        "5.   Fail 5\n",
        "\n",
        "> Issue ->Softmax activation function produces bad results\n",
        "\n",
        "> Solution -> tanh increased the accuracy to 93.3%\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wmzDvREqGTTy"
      }
    }
  ]
}